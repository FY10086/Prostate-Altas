{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0000001",
   "metadata": {},
   "source": [
    "# 02b - Python 批次校正方法\n",
    "\n",
    "本 notebook 包含 4 种基于 Python 的批次校正方法：**scVI**, **scANVI**, **Scanorama**, **BBKNN**。\n",
    "\n",
    "**使用方式**：\n",
    "1. 先在 R notebook (02-Integration.ipynb) 中运行到\"导出数据\"cell\n",
    "2. 在对应的 Python 环境中运行本 notebook\n",
    "3. 运行完后回到 R notebook 导入结果\n",
    "\n",
    "**输入文件**（由 R 导出）：\n",
    "- `counts.mtx`, `genes.txt`, `barcodes.txt`\n",
    "- `metadata.csv`\n",
    "- `hvg.txt`\n",
    "- `pca_embedding.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from scipy.io import mmread\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "import time\n",
    "\n",
    "## ========== 关键参数 ==========\n",
    "input_dir  = \"/home/data/tanglei/project/prostate_altas/output/integration\"\n",
    "output_dir = input_dir\n",
    "batch_key     = \"orig.ident\"   # <-- 与 R 中的 batch_var 保持一致\n",
    "celltype_key  = \"celltype\"     # <-- scANVI 需要\n",
    "n_latent = 30\n",
    "n_epochs = None  # None = 自动决定\n",
    "\n",
    "print(f\"输入/输出目录: {input_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ========== 加载 R 导出的数据 ==========\n",
    "print(\"读取 counts 矩阵...\")\n",
    "counts = mmread(os.path.join(input_dir, \"counts.mtx\")).T.tocsr()  # cells x genes\n",
    "\n",
    "genes = open(os.path.join(input_dir, \"genes.txt\")).read().strip().split(\"\\n\")\n",
    "barcodes = open(os.path.join(input_dir, \"barcodes.txt\")).read().strip().split(\"\\n\")\n",
    "\n",
    "print(\"读取 metadata...\")\n",
    "meta = pd.read_csv(os.path.join(input_dir, \"metadata.csv\"), index_col=0)\n",
    "\n",
    "print(\"读取 HVG 列表...\")\n",
    "hvg = open(os.path.join(input_dir, \"hvg.txt\")).read().strip().split(\"\\n\")\n",
    "\n",
    "print(\"读取 PCA embedding...\")\n",
    "pca_emb = pd.read_csv(os.path.join(input_dir, \"pca_embedding.csv\"), index_col=0)\n",
    "\n",
    "## 构建 AnnData\n",
    "adata = ad.AnnData(\n",
    "    X=counts,\n",
    "    obs=meta.loc[barcodes],\n",
    "    var=pd.DataFrame(index=genes)\n",
    ")\n",
    "adata.obs_names = barcodes\n",
    "adata.var_names = genes\n",
    "\n",
    "## 标记 HVG\n",
    "adata.var[\"highly_variable\"] = adata.var_names.isin(hvg)\n",
    "\n",
    "## 存入 PCA\n",
    "adata.obsm[\"X_pca\"] = pca_emb.loc[adata.obs_names].values\n",
    "\n",
    "## 保存原始 counts 到 raw\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "\n",
    "## 标准化（log1p）供部分方法使用\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "print(f\"AnnData: {adata.shape[0]} cells x {adata.shape[1]} genes\")\n",
    "print(f\"HVG 数量: {sum(adata.var['highly_variable'])}\")\n",
    "print(f\"批次数量: {adata.obs[batch_key].nunique()}\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000004",
   "metadata": {},
   "source": [
    "## 1. scVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvi\n",
    "\n",
    "print(\">>> scVI 开始...\")\n",
    "t0 = time.time()\n",
    "\n",
    "## scVI 需要原始 counts\n",
    "adata_scvi = adata.copy()\n",
    "adata_scvi.X = adata_scvi.layers[\"counts\"].copy()\n",
    "\n",
    "## 只用 HVG\n",
    "adata_scvi = adata_scvi[:, adata_scvi.var[\"highly_variable\"]].copy()\n",
    "\n",
    "## 注册 + 训练\n",
    "scvi.model.SCVI.setup_anndata(\n",
    "    adata_scvi,\n",
    "    layer=\"counts\",\n",
    "    batch_key=batch_key\n",
    ")\n",
    "\n",
    "model_scvi = scvi.model.SCVI(\n",
    "    adata_scvi,\n",
    "    n_latent=n_latent,\n",
    "    n_layers=2,\n",
    "    gene_likelihood=\"zinb\"\n",
    ")\n",
    "\n",
    "model_scvi.train(max_epochs=n_epochs)\n",
    "\n",
    "## 提取 latent embedding\n",
    "scvi_emb = model_scvi.get_latent_representation()\n",
    "scvi_df = pd.DataFrame(\n",
    "    scvi_emb,\n",
    "    index=adata_scvi.obs_names,\n",
    "    columns=[f\"scVI_{i+1}\" for i in range(scvi_emb.shape[1])]\n",
    ")\n",
    "\n",
    "## 保存\n",
    "scvi_df.to_csv(os.path.join(output_dir, \"scvi_embedding.csv\"))\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"scVI 完成! 耗时: {elapsed:.1f} 秒\")\n",
    "print(f\"Embedding shape: {scvi_df.shape}\")\n",
    "\n",
    "## 存入 adata 用于后续可视化\n",
    "adata.obsm[\"X_scVI\"] = scvi_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000006",
   "metadata": {},
   "source": [
    "## 2. scANVI（监督版 scVI）\n",
    "\n",
    "scANVI 利用已知的细胞类型标签进行半监督整合。需要 `celltype` 列。  \n",
    "如果部分细胞没有标签，设为 `\"Unknown\"` 即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>> scANVI 开始...\")\n",
    "t0 = time.time()\n",
    "\n",
    "## 从已训练的 scVI 模型初始化 scANVI\n",
    "## 处理缺失标签：NaN/空值 -> \"Unknown\"\n",
    "adata_scvi.obs[\"celltype_scanvi\"] = adata_scvi.obs[celltype_key].fillna(\"Unknown\").astype(str)\n",
    "adata_scvi.obs.loc[adata_scvi.obs[\"celltype_scanvi\"] == \"\", \"celltype_scanvi\"] = \"Unknown\"\n",
    "\n",
    "model_scanvi = scvi.model.SCANVI.from_scvi_model(\n",
    "    model_scvi,\n",
    "    adata=adata_scvi,\n",
    "    labels_key=\"celltype_scanvi\",\n",
    "    unlabeled_category=\"Unknown\"\n",
    ")\n",
    "\n",
    "model_scanvi.train(max_epochs=20)\n",
    "\n",
    "## 提取 latent embedding\n",
    "scanvi_emb = model_scanvi.get_latent_representation()\n",
    "scanvi_df = pd.DataFrame(\n",
    "    scanvi_emb,\n",
    "    index=adata_scvi.obs_names,\n",
    "    columns=[f\"scANVI_{i+1}\" for i in range(scanvi_emb.shape[1])]\n",
    ")\n",
    "\n",
    "## 保存\n",
    "scanvi_df.to_csv(os.path.join(output_dir, \"scanvi_embedding.csv\"))\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"scANVI 完成! 耗时: {elapsed:.1f} 秒\")\n",
    "print(f\"Embedding shape: {scanvi_df.shape}\")\n",
    "\n",
    "adata.obsm[\"X_scANVI\"] = scanvi_emb\n",
    "\n",
    "## 清理 scVI/scANVI 临时对象\n",
    "del adata_scvi, model_scvi, model_scanvi\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000008",
   "metadata": {},
   "source": [
    "## 3. Scanorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanorama\n",
    "\n",
    "print(\">>> Scanorama 开始...\")\n",
    "t0 = time.time()\n",
    "\n",
    "## Scanorama 需要按 batch 分割的 list\n",
    "adata_sca = adata.copy()\n",
    "adata_sca = adata_sca[:, adata_sca.var[\"highly_variable\"]].copy()\n",
    "\n",
    "batches = adata_sca.obs[batch_key].unique().tolist()\n",
    "adatas_list = [adata_sca[adata_sca.obs[batch_key] == b].copy() for b in batches]\n",
    "\n",
    "## 运行 Scanorama\n",
    "scanorama.integrate_scanpy(adatas_list, dimred=n_latent)\n",
    "\n",
    "## 合并 embedding\n",
    "scanorama_emb = np.concatenate([a.obsm[\"X_scanorama\"] for a in adatas_list], axis=0)\n",
    "scanorama_cells = np.concatenate([a.obs_names.tolist() for a in adatas_list])\n",
    "\n",
    "scanorama_df = pd.DataFrame(\n",
    "    scanorama_emb,\n",
    "    index=scanorama_cells,\n",
    "    columns=[f\"Scanorama_{i+1}\" for i in range(scanorama_emb.shape[1])]\n",
    ")\n",
    "## 按原始 cell 顺序重排\n",
    "scanorama_df = scanorama_df.loc[adata.obs_names]\n",
    "\n",
    "## 保存\n",
    "scanorama_df.to_csv(os.path.join(output_dir, \"scanorama_embedding.csv\"))\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"Scanorama 完成! 耗时: {elapsed:.1f} 秒\")\n",
    "print(f\"Embedding shape: {scanorama_df.shape}\")\n",
    "\n",
    "adata.obsm[\"X_Scanorama\"] = scanorama_df.values\n",
    "\n",
    "del adata_sca, adatas_list\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000010",
   "metadata": {},
   "source": [
    "## 4. BBKNN\n",
    "\n",
    "BBKNN 不产生 corrected embedding，而是直接在 PCA 空间构建 batch-balanced kNN graph。  \n",
    "因此我们导出基于 BBKNN graph 的 UMAP 坐标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bbknn\n",
    "\n",
    "print(\">>> BBKNN 开始...\")\n",
    "t0 = time.time()\n",
    "\n",
    "adata_bbknn = adata.copy()\n",
    "\n",
    "## BBKNN 在 PCA 空间上工作\n",
    "bbknn.bbknn(adata_bbknn, batch_key=batch_key, n_pcs=30)\n",
    "\n",
    "## 基于 BBKNN graph 计算 UMAP\n",
    "sc.tl.umap(adata_bbknn)\n",
    "\n",
    "## 导出 UMAP 坐标（BBKNN 不产生 embedding，graph 无法直接传给 R）\n",
    "bbknn_umap = pd.DataFrame(\n",
    "    adata_bbknn.obsm[\"X_umap\"],\n",
    "    index=adata_bbknn.obs_names,\n",
    "    columns=[\"BBKNN_UMAP_1\", \"BBKNN_UMAP_2\"]\n",
    ")\n",
    "bbknn_umap.to_csv(os.path.join(output_dir, \"bbknn_umap.csv\"))\n",
    "\n",
    "## 同时导出 BBKNN 后的 connectivities 和 distances 以便 R 中进一步分析\n",
    "## 以及利用 BBKNN graph 做 diffmap 得到更高维 embedding 用于 benchmark\n",
    "sc.tl.diffmap(adata_bbknn, n_comps=30)\n",
    "bbknn_emb = pd.DataFrame(\n",
    "    adata_bbknn.obsm[\"X_diffmap\"][:, :30],\n",
    "    index=adata_bbknn.obs_names,\n",
    "    columns=[f\"BBKNN_{i+1}\" for i in range(30)]\n",
    ")\n",
    "bbknn_emb.to_csv(os.path.join(output_dir, \"bbknn_embedding.csv\"))\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"BBKNN 完成! 耗时: {elapsed:.1f} 秒\")\n",
    "print(f\"UMAP shape: {bbknn_umap.shape}\")\n",
    "print(f\"Diffmap embedding shape: {bbknn_emb.shape}\")\n",
    "\n",
    "del adata_bbknn\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000012",
   "metadata": {},
   "source": [
    "## 汇总可视化（可选）\n",
    "\n",
    "在 Python 中快速查看各方法的 UMAP。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "methods_obsm = {\n",
    "    \"scVI\": \"X_scVI\",\n",
    "    \"scANVI\": \"X_scANVI\",\n",
    "    \"Scanorama\": \"X_Scanorama\"\n",
    "}\n",
    "\n",
    "for ax, (name, key) in zip(axes.flat[:3], methods_obsm.items()):\n",
    "    ## 对每种 embedding 计算 UMAP\n",
    "    sc.pp.neighbors(adata, use_rep=key, n_neighbors=30)\n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata, color=batch_key, ax=ax, show=False, title=name,\n",
    "               legend_loc=\"none\", frameon=True, size=1)\n",
    "\n",
    "## BBKNN 已有 UMAP\n",
    "ax = axes.flat[3]\n",
    "bbknn_umap_vals = pd.read_csv(os.path.join(output_dir, \"bbknn_umap.csv\"), index_col=0)\n",
    "ax.scatter(bbknn_umap_vals.iloc[:, 0], bbknn_umap_vals.iloc[:, 1],\n",
    "           c=\"gray\", s=0.5, alpha=0.3)\n",
    "ax.set_title(\"BBKNN\")\n",
    "ax.set_xlabel(\"UMAP1\")\n",
    "ax.set_ylabel(\"UMAP2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"python_methods_umap.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Python 方法全部完成！结果已保存到:\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
